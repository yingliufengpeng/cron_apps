ssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x00000203D15667B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Traceback (most recent call last):
  File "E:\cron_tasks\app.py", line 23, in <module>
    file_handler = logging.FileHandler("logs/plombery.log", encoding="utf-8")
  File "E:\apps\miniconda3\Lib\logging\__init__.py", line 1219, in __init__
    StreamHandler.__init__(self, self._open())
                                 ~~~~~~~~~~^^
  File "E:\apps\miniconda3\Lib\logging\__init__.py", line 1248, in _open
    return open_func(self.baseFilename, self.mode,
                     encoding=self.encoding, errors=self.errors)
PermissionError: [Errno 13] Permission denied: 'E:\\cron_tasks\\logs\\plombery.log'
ssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x00000209DD6267B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Traceback (most recent call last):
  File "E:\cron_tasks\app.py", line 23, in <module>
    file_handler = logging.FileHandler("logs/plombery.log", encoding="utf-8")
  File "E:\apps\miniconda3\Lib\logging\__init__.py", line 1219, in __init__
    StreamHandler.__init__(self, self._open())
                                 ~~~~~~~~~~^^
  File "E:\apps\miniconda3\Lib\logging\__init__.py", line 1248, in _open
    return open_func(self.baseFilename, self.mode,
                     encoding=self.encoding, errors=self.errors)
PermissionError: [Errno 13] Permission denied: 'E:\\cron_tasks\\logs\\plombery.log'
ssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x000001B03CA367B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Traceback (most recent call last):
  File "E:\cron_tasks\app.py", line 23, in <module>
    file_handler = logging.FileHandler("logs/plombery.log", encoding="utf-8")
  File "E:\apps\miniconda3\Lib\logging\__init__.py", line 1219, in __init__
    StreamHandler.__init__(self, self._open())
                                 ~~~~~~~~~~^^
  File "E:\apps\miniconda3\Lib\logging\__init__.py", line 1248, in _open
    return open_func(self.baseFilename, self.mode,
                     encoding=self.encoding, errors=self.errors)
PermissionError: [Errno 13] Permission denied: 'E:\\cron_tasks\\logs\\plombery.log'
ssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x0000018B64A367B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Traceback (most recent call last):
  File "E:\cron_tasks\app.py", line 23, in <module>
    file_handler = logging.FileHandler("logs/plombery.log", encoding="utf-8")
  File "E:\apps\miniconda3\Lib\logging\__init__.py", line 1219, in __init__
    StreamHandler.__init__(self, self._open())
                                 ~~~~~~~~~~^^
  File "E:\apps\miniconda3\Lib\logging\__init__.py", line 1248, in _open
    return open_func(self.baseFilename, self.mode,
                     encoding=self.encoding, errors=self.errors)
PermissionError: [Errno 13] Permission denied: 'E:\\cron_tasks\\logs\\plombery.log'
ssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x000002144FFC67B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Traceback (most recent call last):
  File "E:\cron_tasks\app.py", line 8, in <module>
    from plombery import Trigger, register_pipeline
  File "E:\apps\miniconda3\Lib\site-packages\plombery\__init__.py", line 10, in <module>
    from .database.operations import setup_database
  File "E:\apps\miniconda3\Lib\site-packages\plombery\database\operations.py", line 3, in <module>
    from alembic import command
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\alembic\__init__.py", line 1, in <module>
    from . import context
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\alembic\context.py", line 1, in <module>
    from .runtime.environment import EnvironmentContext
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\alembic\runtime\environment.py", line 23, in <module>
    from .migration import _ProxyTransaction
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\alembic\runtime\migration.py", line 32, in <module>
    from .. import ddl
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\alembic\ddl\__init__.py", line 4, in <module>
    from . import postgresql
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\alembic\ddl\postgresql.py", line 47, in <module>
    from ..autogenerate import render
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\alembic\autogenerate\__init__.py", line 1, in <module>
    from .api import _render_migration_diffs as _render_migration_diffs
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 1023, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1156, in get_code
  File "<frozen importlib._bootstrap_external>", line 787, in _compile_bytecode
  File "<frozen importlib._bootstrap>", line 491, in _verbose_message
KeyboardInterrupt
^Cssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x000001CD0D2A67B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Traceback (most recent call last):
  File "E:\cron_tasks\app.py", line 46, in <module>
    raise UserWarning("fsfsf")
UserWarning: fsfsf
ssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x000002068A4467B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Traceback (most recent call last):
  File "E:\cron_tasks\app.py", line 46, in <module>
    raise UserWarning("fsfsf")
UserWarning: fsfsf
ssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x000001D4EE2167B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Traceback (most recent call last):
  File "E:\cron_tasks\app.py", line 46, in <module>
    raise UserWarning("fsfsf")
UserWarning: fsfsf
INFO:     Started server process [33468]
INFO:     Waiting for application startup.
ssss E:\apps\miniconda3\python.exe, [<_distutils_hack.DistutilsMetaFinder object at 0x0000025ED94D67B0>, <class '_frozen_importlib.BuiltinImporter'>, <class '_frozen_importlib.FrozenImporter'>, <class '_frozen_importlib_external.PathFinder'>]
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
Alembic migrations complete.
INFO:     127.0.0.1:53312 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:62919 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:53312 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:53312 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:52875 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:49452 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:49452 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #5 via trigger `_manual`
INFO  [plombery.5] Executing pipeline `download_pipeline` #5 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.5] Executing task download_and_delete_mp4
Running download_and_delete_mp4 at 2025-12-09 17:13:56.114528
INFO:     127.0.0.1:49452 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:56178 - "GET /api/runs/5 HTTP/1.1" 200 OK
INFO:     127.0.0.1:56178 - "GET /api/runs/5/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:56776 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:62093 - "GET /api/runs/5 HTTP/1.1" 200 OK
INFO:     127.0.0.1:51908 - "GET /api/runs/5/logs HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [33468]
INFO:     Started server process [18100]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:56648 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Alembic migrations complete.
INFO:     127.0.0.1:64712 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:49487 - "GET /api/runs/5 HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET /api/runs/5/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:49487 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:49487 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:49487 - "GET /assets/index-D7hlsBy4.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:55437 - "GET /assets/index-CZhli8kz.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:55437 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET /logo.svg HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:55437 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:49487 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:49452 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:49487 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:49487 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:50135 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:49487 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:50480 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:55437 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:49487 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:49487 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:53768 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:49487 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:49487 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:54611 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:55437 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:55437 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:49487 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:63086 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:58747 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:58747 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:58747 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #6 via trigger `_manual`
INFO  [plombery.6] Executing pipeline `download_pipeline` #6 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.6] Executing task download_and_delete_mp4
Running download_and_delete_mp4 at 2025-12-09 17:22:48.184142
INFO:     127.0.0.1:58747 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:63086 - "GET /api/runs/6 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63086 - "GET /api/runs/6/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:61389 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:64963 - "GET /api/runs/6 HTTP/1.1" 200 OK
INFO:     127.0.0.1:60278 - "GET /api/runs/6/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:60278 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:64963 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:64963 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:64963 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #7 via trigger `_manual`
INFO  [plombery.7] Executing pipeline `download_pipeline` #7 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.7] Executing task download_and_delete_mp4
Running download_and_delete_mp4 at 2025-12-09 17:49:11.222804
INFO:     127.0.0.1:64963 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:60278 - "GET /api/runs/7 HTTP/1.1" 200 OK
INFO:     127.0.0.1:60278 - "GET /api/runs/7/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:49452 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:59255 - "GET /api/runs/7 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65519 - "GET /api/runs/7/logs HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [18100]
INFO:     Started server process [34436]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:50939 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Alembic migrations complete.
INFO:     127.0.0.1:55661 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:57546 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:57546 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:55661 - "GET /assets/index-CZhli8kz.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:57546 - "GET /assets/index-D7hlsBy4.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:59633 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:57546 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:57546 - "GET /logo.svg HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:57546 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:55661 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:55661 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:55661 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #8 via trigger `_manual`
INFO  [plombery.8] Executing pipeline `download_pipeline` #8 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.8] Executing task download_and_delete_mp4
E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
Cancellation requested; stopping current tasks.
ERROR [apscheduler.executors.default] Job "run (trigger: date[2025-12-09 17:49:53 +08], pending)" raised an exception
Traceback (most recent call last):
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\apscheduler\executors\base.py", line 181, in run_coroutine_job
    retval = await job.func(*job.args, **job.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\orchestrator\executor.py", line 130, in run
    flowing_data = await _execute_task(task, flowing_data, pipeline_params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\orchestrator\executor.py", line 208, in _execute_task
    result = await task.run(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\pipeline\__init__.py", line 15, in wrapper_decorator
    value = await func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\cron_apps\jobs\task.py", line 28, in download_and_delete_mp4
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py", line 89, in _inner_fn
    return fn(*args, **kwargs)
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1024, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
        # Destination
    ...<15 lines>...
        dry_run=dry_run,
    )
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1240, in _hf_hub_download_to_cache_dir
    _download_to_tmp_and_move(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        incomplete_path=Path(blob_path + ".incomplete"),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<8 lines>...
        tqdm_class=tqdm_class,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1864, in _download_to_tmp_and_move
    xet_get(
    ~~~~~~~^
        incomplete_path=incomplete_path,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        tqdm_class=tqdm_class,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 588, in xet_get
    download_files(
    ~~~~~~~~~~~~~~^
        xet_download_info,
        ^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        progress_updater=[progress_updater],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
KeyboardInterrupt
INFO:     127.0.0.1:63715 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:50760 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:63060 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:63404 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:51961 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:52173 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:58526 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:61992 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:59664 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:60138 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Running download_and_delete_mp4 at 2025-12-09 17:49:53.219054
仓库文件总数：185
已下载：.gitattributes -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
已下载：LICENSE-CODE -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
已下载：LICENSE-MODEL -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
已下载：README.md -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
已下载：README_WEIGHTS.md -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
已下载：config.json -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
已下载：configuration_deepseek.py -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
已下载：figures/benchmark.png -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
已下载：figures/niah.png -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
已下载：inference/configs/config_16B.json -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
已下载：inference/configs/config_236B.json -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_236B.json
已下载：inference/configs/config_671B.json -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_671B.json
已下载：inference/convert.py -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\convert.py
已下载：inference/fp8_cast_bf16.py -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\fp8_cast_bf16.py
已下载：inference/generate.py -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\generate.py
已下载：inference/kernel.py -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\kernel.py
已下载：inference/model.py -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\model.py
已下载：inference/requirements.txt -> tmp\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\requirements.txt
INFO:     127.0.0.1:49452 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:65520 - "GET /api/runs/8 HTTP/1.1" 200 OK
INFO:     127.0.0.1:65520 - "GET /api/runs/8/logs HTTP/1.1" 200 OK
INFO:     Started server process [35896]
INFO:     Waiting for application startup.
已清除代理设置。
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:58169 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Alembic migrations complete.
INFO:     127.0.0.1:49540 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:53884 - "GET /api/runs/8 HTTP/1.1" 200 OK
INFO:     127.0.0.1:49454 - "GET /api/runs/8/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:49454 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:53884 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:53884 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:53884 - "GET /assets/index-D7hlsBy4.js HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:53884 - "GET /assets/index-CZhli8kz.css HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:64897 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:53884 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:53884 - "GET /logo.svg HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:53884 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:49454 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:49454 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:49454 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #9 via trigger `_manual`
INFO  [plombery.9] Executing pipeline `download_pipeline` #9 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.9] Executing task download_and_delete_mp4
E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
Cancellation requested; stopping current tasks.
ERROR [apscheduler.executors.default] Job "run (trigger: date[2025-12-09 18:25:41 +08], pending)" raised an exception
Traceback (most recent call last):
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\apscheduler\executors\base.py", line 181, in run_coroutine_job
    retval = await job.func(*job.args, **job.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\orchestrator\executor.py", line 130, in run
    flowing_data = await _execute_task(task, flowing_data, pipeline_params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\orchestrator\executor.py", line 208, in _execute_task
    result = await task.run(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\pipeline\__init__.py", line 15, in wrapper_decorator
    value = await func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\cron_apps\jobs\task.py", line 17, in download_and_delete_mp4
    await hugging_face_hub_download.download_and_delete_mp4()
  File "E:\cron_apps\hugging_face_hub_download.py", line 39, in download_and_delete_mp4
    try:
    
    ...<4 lines>...
            resume_download=True,  # 支持断点续传
    
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py", line 89, in _inner_fn
    return fn(*args, **kwargs)
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1024, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
        # Destination
    ...<15 lines>...
        dry_run=dry_run,
    )
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1240, in _hf_hub_download_to_cache_dir
    _download_to_tmp_and_move(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        incomplete_path=Path(blob_path + ".incomplete"),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<8 lines>...
        tqdm_class=tqdm_class,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1864, in _download_to_tmp_and_move
    xet_get(
    ~~~~~~~^
        incomplete_path=incomplete_path,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        tqdm_class=tqdm_class,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 588, in xet_get
    download_files(
    ~~~~~~~~~~~~~~^
        xet_download_info,
        ^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        progress_updater=[progress_updater],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
KeyboardInterrupt
INFO:     127.0.0.1:59316 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:51455 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:58844 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:60894 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Running download_and_delete_mp4 at 2025-12-09 18:25:41.251556
仓库文件总数：185
正在下载：model-00158-of-000163.safetensors
INFO:     127.0.0.1:56510 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:51268 - "GET /api/runs/9 HTTP/1.1" 200 OK
INFO:     127.0.0.1:51268 - "GET /api/runs/9/logs HTTP/1.1" 200 OK
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 11, in <module>
    logger.info("已清除代理设置。")
    ^^^^^^
NameError: name 'logger' is not defined
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 11, in <module>
    logger.info("已清除代理设置。")
    ^^^^^^
NameError: name 'logger' is not defined
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 11, in <module>
    logger.info("已清除代理设置。")
    ^^^^^^
NameError: name 'logger' is not defined
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 11, in <module>
    logger.info("已清除代理设置。")
    ^^^^^^
NameError: name 'logger' is not defined
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 11, in <module>
    logger.info("已清除代理设置。")
    ^^^^^^
NameError: name 'logger' is not defined
INFO:     Started server process [11076]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
Alembic migrations complete.
INFO:     127.0.0.1:59613 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:53223 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:59613 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:59613 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:61161 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:61161 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:61161 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #10 via trigger `_manual`
INFO  [plombery.10] Executing pipeline `download_pipeline` #10 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.10] Executing task download_and_delete_mp4
仓库文件总数：185
INFO  [plombery] 仓库文件总数：185
正在下载：model-00158-of-000163.safetensors
INFO  [plombery] 正在下载：model-00158-of-000163.safetensors
E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
Cancellation requested; stopping current tasks.
ERROR [apscheduler.executors.default] Job "run (trigger: date[2025-12-09 18:29:56 +08], pending)" raised an exception
Traceback (most recent call last):
  File "C:\Users\peng\AppData\Roaming\Python\Python313\site-packages\apscheduler\executors\base.py", line 181, in run_coroutine_job
    retval = await job.func(*job.args, **job.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\orchestrator\executor.py", line 130, in run
    flowing_data = await _execute_task(task, flowing_data, pipeline_params)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\orchestrator\executor.py", line 208, in _execute_task
    result = await task.run(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\apps\miniconda3\Lib\site-packages\plombery\pipeline\__init__.py", line 15, in wrapper_decorator
    value = await func(*args, **kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\cron_apps\jobs\task.py", line 17, in download_and_delete_mp4
    await hugging_face_hub_download.download_and_delete_mp4()
  File "E:\cron_apps\hugging_face_hub_download.py", line 40, in download_and_delete_mp4
    _logger.info(f"正在下载：{filename}")
                     ^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
            cache_dir=local_dir,  # 本地缓存目录
    
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py", line 89, in _inner_fn
    return fn(*args, **kwargs)
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1024, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
        # Destination
    ...<15 lines>...
        dry_run=dry_run,
    )
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1240, in _hf_hub_download_to_cache_dir
    _download_to_tmp_and_move(
    ~~~~~~~~~~~~~~~~~~~~~~~~~^
        incomplete_path=Path(blob_path + ".incomplete"),
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<8 lines>...
        tqdm_class=tqdm_class,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 1864, in _download_to_tmp_and_move
    xet_get(
    ~~~~~~~^
        incomplete_path=incomplete_path,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    ...<4 lines>...
        tqdm_class=tqdm_class,
        ^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "E:\apps\miniconda3\Lib\site-packages\huggingface_hub\file_download.py", line 588, in xet_get
    download_files(
    ~~~~~~~~~~~~~~^
        xet_download_info,
        ^^^^^^^^^^^^^^^^^^
    ...<3 lines>...
        progress_updater=[progress_updater],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
KeyboardInterrupt
INFO:     127.0.0.1:60813 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:53677 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Running download_and_delete_mp4 at 2025-12-09 18:29:56.330494
INFO:     127.0.0.1:58190 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:64571 - "GET /api/runs/10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64571 - "GET /api/runs/10/logs HTTP/1.1" 200 OK
INFO:     Started server process [10048]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
Alembic migrations complete.
INFO:     127.0.0.1:64401 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:64401 - "GET /api/runs/10 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64401 - "GET /api/runs/10/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:49622 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:64401 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:56532 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:56532 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:64039 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:56532 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:56532 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:64401 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:64401 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:64401 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #11 via trigger `_manual`
INFO  [plombery.11] Executing pipeline `download_pipeline` #11 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.11] Executing task download_and_delete_mp4
仓库文件总数：185
INFO  [plombery] 仓库文件总数：185
正在下载：.gitattributes
INFO  [plombery] 正在下载：.gitattributes
E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
已下载：.gitattributes -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
INFO  [plombery] 已下载：.gitattributes -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
正在下载：LICENSE-CODE
INFO  [plombery] 正在下载：LICENSE-CODE
已下载：LICENSE-CODE -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
INFO  [plombery] 已下载：LICENSE-CODE -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
正在下载：LICENSE-MODEL
INFO  [plombery] 正在下载：LICENSE-MODEL
已下载：LICENSE-MODEL -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
INFO  [plombery] 已下载：LICENSE-MODEL -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
正在下载：README.md
INFO  [plombery] 正在下载：README.md
已下载：README.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
INFO  [plombery] 已下载：README.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
正在下载：README_WEIGHTS.md
INFO  [plombery] 正在下载：README_WEIGHTS.md
已下载：README_WEIGHTS.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
INFO  [plombery] 已下载：README_WEIGHTS.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
正在下载：config.json
INFO  [plombery] 正在下载：config.json
已下载：config.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
INFO  [plombery] 已下载：config.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
正在下载：configuration_deepseek.py
INFO  [plombery] 正在下载：configuration_deepseek.py
已下载：configuration_deepseek.py -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
INFO  [plombery] 已下载：configuration_deepseek.py -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
正在下载：figures/benchmark.png
INFO  [plombery] 正在下载：figures/benchmark.png
已下载：figures/benchmark.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
INFO  [plombery] 已下载：figures/benchmark.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
正在下载：figures/niah.png
INFO  [plombery] 正在下载：figures/niah.png
已下载：figures/niah.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
INFO  [plombery] 已下载：figures/niah.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
正在下载：inference/configs/config_16B.json
INFO  [plombery] 正在下载：inference/configs/config_16B.json
已下载：inference/configs/config_16B.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
INFO  [plombery] 已下载：inference/configs/config_16B.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
下载完成
INFO  [plombery] 下载完成
tmp/deepseek-ai/DeepSeek-V3 已删除
INFO  [plombery] tmp/deepseek-ai/DeepSeek-V3 已删除
Running download_and_delete_mp4 at 2025-12-09 18:31:27.523164
INFO:     127.0.0.1:51366 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:63824 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:51366 - "GET /api/runs/11 HTTP/1.1" 200 OK
INFO:     127.0.0.1:51366 - "GET /api/runs/11/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:54474 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:50586 - "GET /api/runs/11 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63965 - "GET /api/runs/11/logs HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [10048]
INFO:     Started server process [36240]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:60842 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Alembic migrations complete.
INFO:     127.0.0.1:64117 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:54168 - "GET /api/runs/11/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:60588 - "GET /api/runs/11 HTTP/1.1" 200 OK
INFO:     127.0.0.1:60588 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:54168 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:54168 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:54168 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #12 via trigger `_manual`
INFO  [plombery.12] Executing pipeline `download_pipeline` #12 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.12] Executing task download_and_delete_mp4
仓库文件总数：185
INFO  [plombery] 仓库文件总数：185
正在下载：.gitattributes
INFO  [plombery] 正在下载：.gitattributes
E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
已下载：.gitattributes -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
INFO  [plombery] 已下载：.gitattributes -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
正在下载：LICENSE-CODE
INFO  [plombery] 正在下载：LICENSE-CODE
已下载：LICENSE-CODE -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
INFO  [plombery] 已下载：LICENSE-CODE -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
正在下载：LICENSE-MODEL
INFO  [plombery] 正在下载：LICENSE-MODEL
已下载：LICENSE-MODEL -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
INFO  [plombery] 已下载：LICENSE-MODEL -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
正在下载：README.md
INFO  [plombery] 正在下载：README.md
已下载：README.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
INFO  [plombery] 已下载：README.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
正在下载：README_WEIGHTS.md
INFO  [plombery] 正在下载：README_WEIGHTS.md
已下载：README_WEIGHTS.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
INFO  [plombery] 已下载：README_WEIGHTS.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
正在下载：config.json
INFO  [plombery] 正在下载：config.json
已下载：config.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
INFO  [plombery] 已下载：config.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
正在下载：configuration_deepseek.py
INFO  [plombery] 正在下载：configuration_deepseek.py
已下载：configuration_deepseek.py -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
INFO  [plombery] 已下载：configuration_deepseek.py -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
正在下载：figures/benchmark.png
INFO  [plombery] 正在下载：figures/benchmark.png
已下载：figures/benchmark.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
INFO  [plombery] 已下载：figures/benchmark.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
正在下载：figures/niah.png
INFO  [plombery] 正在下载：figures/niah.png
已下载：figures/niah.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
INFO  [plombery] 已下载：figures/niah.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
正在下载：inference/configs/config_16B.json
INFO  [plombery] 正在下载：inference/configs/config_16B.json
已下载：inference/configs/config_16B.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
INFO  [plombery] 已下载：inference/configs/config_16B.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
下载完成
INFO  [plombery] 下载完成
tmp/deepseek-ai/DeepSeek-V3 已删除
INFO  [plombery] tmp/deepseek-ai/DeepSeek-V3 已删除
Running download_and_delete_mp4 at 2025-12-09 18:33:36.529975
INFO:     127.0.0.1:54606 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:62377 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:54606 - "GET /api/runs/12 HTTP/1.1" 200 OK
INFO:     127.0.0.1:54606 - "GET /api/runs/12/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:55634 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:52575 - "GET /api/runs/12 HTTP/1.1" 200 OK
INFO:     127.0.0.1:54730 - "GET /api/runs/12/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:52896 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:50060 - "GET /api/runs/12 HTTP/1.1" 200 OK
INFO:     127.0.0.1:57171 - "GET /api/runs/12/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:53506 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:62675 - "GET /api/runs/12 HTTP/1.1" 200 OK
INFO:     127.0.0.1:52254 - "GET /api/runs/12/logs HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [36240]
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x00000193464AA110>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x0000028977E9A0C0>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000001E76DEBA110>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000001FB2C03A070>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000002118FD6A070>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x00000221ADD6A160>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000001BF7F13A0C0>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000002195259A110>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000001206AA19F80>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000001F6821CA020>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x00000249F115A0C0>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000001B1CDD3A070>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000002886D31A200>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000001B15CE99FD0>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x0000011A51D3A0C0>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x0000029AEDA4A0C0>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000002B3FF96A0C0>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x0000015DD1E4A250>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000002BE6CA30040>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x000001BEBB91A070>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x00000126A58FA070>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x0000019ECDB6A200>
Traceback (most recent call last):
  File "E:\cron_apps\app.py", line 15, in <module>
    from jobs.task import download_and_delete_mp4
  File "E:\cron_apps\jobs\task.py", line 9, in <module>
    _logger = get_logger()
  File "E:\apps\miniconda3\Lib\site-packages\plombery\logger\__init__.py", line 18, in get_logger
    pipeline = pipeline_context.get()
LookupError: <ContextVar name='pipeline' at 0x00000232BF2B0040>
INFO:     Started server process [23224]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
Alembic migrations complete.
INFO:     127.0.0.1:62224 - "GET /pipelines/download_pipeline/triggers/_manual/runs/12 HTTP/1.1" 200 OK
INFO:     127.0.0.1:59849 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:62224 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:63631 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:62224 - "GET /api/runs/12 HTTP/1.1" 200 OK
INFO:     127.0.0.1:62224 - "GET /api/runs/12/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:62224 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:63631 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:63631 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:63631 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #13 via trigger `_manual`
INFO  [plombery.13] Executing pipeline `download_pipeline` #13 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.13] Executing task download_and_delete_mp4
Running download_and_delete_mp4 at 2025-12-09 18:40:04.557816
INFO  [plombery.13-download_and_delete_mp4] Running download_and_delete_mp4 at 2025-12-09 18:40:04.557816
仓库文件总数：185
INFO  [plombery.13-download_and_delete_mp4] 仓库文件总数：185
正在下载：.gitattributes
INFO  [plombery.13-download_and_delete_mp4] 正在下载：.gitattributes
E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
已下载：.gitattributes -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
INFO  [plombery.13-download_and_delete_mp4] 已下载：.gitattributes -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
正在下载：LICENSE-CODE
INFO  [plombery.13-download_and_delete_mp4] 正在下载：LICENSE-CODE
已下载：LICENSE-CODE -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
INFO  [plombery.13-download_and_delete_mp4] 已下载：LICENSE-CODE -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
正在下载：LICENSE-MODEL
INFO  [plombery.13-download_and_delete_mp4] 正在下载：LICENSE-MODEL
已下载：LICENSE-MODEL -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
INFO  [plombery.13-download_and_delete_mp4] 已下载：LICENSE-MODEL -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
正在下载：README.md
INFO  [plombery.13-download_and_delete_mp4] 正在下载：README.md
已下载：README.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
INFO  [plombery.13-download_and_delete_mp4] 已下载：README.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
正在下载：README_WEIGHTS.md
INFO  [plombery.13-download_and_delete_mp4] 正在下载：README_WEIGHTS.md
已下载：README_WEIGHTS.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
INFO  [plombery.13-download_and_delete_mp4] 已下载：README_WEIGHTS.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
正在下载：config.json
INFO  [plombery.13-download_and_delete_mp4] 正在下载：config.json
已下载：config.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
INFO  [plombery.13-download_and_delete_mp4] 已下载：config.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
正在下载：configuration_deepseek.py
INFO  [plombery.13-download_and_delete_mp4] 正在下载：configuration_deepseek.py
已下载：configuration_deepseek.py -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
INFO  [plombery.13-download_and_delete_mp4] 已下载：configuration_deepseek.py -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
正在下载：figures/benchmark.png
INFO  [plombery.13-download_and_delete_mp4] 正在下载：figures/benchmark.png
已下载：figures/benchmark.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
INFO  [plombery.13-download_and_delete_mp4] 已下载：figures/benchmark.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
正在下载：figures/niah.png
INFO  [plombery.13-download_and_delete_mp4] 正在下载：figures/niah.png
已下载：figures/niah.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
INFO  [plombery.13-download_and_delete_mp4] 已下载：figures/niah.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
正在下载：inference/configs/config_16B.json
INFO  [plombery.13-download_and_delete_mp4] 正在下载：inference/configs/config_16B.json
已下载：inference/configs/config_16B.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
INFO  [plombery.13-download_and_delete_mp4] 已下载：inference/configs/config_16B.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
下载完成
INFO  [plombery.13-download_and_delete_mp4] 下载完成
tmp/deepseek-ai/DeepSeek-V3 已删除
INFO  [plombery.13-download_and_delete_mp4] tmp/deepseek-ai/DeepSeek-V3 已删除
INFO:     127.0.0.1:65519 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:50173 - "GET /api/runs/13 HTTP/1.1" 200 OK
INFO:     127.0.0.1:50173 - "GET /api/runs/13/logs HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [23224]
INFO:     Started server process [7128]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:56491 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Alembic migrations complete.
INFO:     127.0.0.1:54485 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:51541 - "GET /api/runs/13 HTTP/1.1" 200 OK
INFO:     127.0.0.1:63243 - "GET /api/runs/13/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:63243 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:51541 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:51541 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:51541 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #14 via trigger `_manual`
INFO  [plombery.14] Executing pipeline `download_pipeline` #14 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.14] Executing task download_and_delete_mp4
Running download_and_delete_mp4 at 2025-12-09 18:41:45.673558
INFO  [plombery.14-download_and_delete_mp4] Running download_and_delete_mp4 at 2025-12-09 18:41:45.673558
仓库文件总数：185
INFO  [plombery.14-download_and_delete_mp4] 仓库文件总数：185
正在下载：.gitattributes
INFO  [plombery.14-download_and_delete_mp4] 正在下载：.gitattributes
E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
已下载：.gitattributes -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
INFO  [plombery.14-download_and_delete_mp4] 已下载：.gitattributes -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\.gitattributes
正在下载：LICENSE-CODE
INFO  [plombery.14-download_and_delete_mp4] 正在下载：LICENSE-CODE
已下载：LICENSE-CODE -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
INFO  [plombery.14-download_and_delete_mp4] 已下载：LICENSE-CODE -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-CODE
正在下载：LICENSE-MODEL
INFO  [plombery.14-download_and_delete_mp4] 正在下载：LICENSE-MODEL
已下载：LICENSE-MODEL -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
INFO  [plombery.14-download_and_delete_mp4] 已下载：LICENSE-MODEL -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\LICENSE-MODEL
正在下载：README.md
INFO  [plombery.14-download_and_delete_mp4] 正在下载：README.md
已下载：README.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
INFO  [plombery.14-download_and_delete_mp4] 已下载：README.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README.md
正在下载：README_WEIGHTS.md
INFO  [plombery.14-download_and_delete_mp4] 正在下载：README_WEIGHTS.md
已下载：README_WEIGHTS.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
INFO  [plombery.14-download_and_delete_mp4] 已下载：README_WEIGHTS.md -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\README_WEIGHTS.md
正在下载：config.json
INFO  [plombery.14-download_and_delete_mp4] 正在下载：config.json
已下载：config.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
INFO  [plombery.14-download_and_delete_mp4] 已下载：config.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\config.json
正在下载：configuration_deepseek.py
INFO  [plombery.14-download_and_delete_mp4] 正在下载：configuration_deepseek.py
已下载：configuration_deepseek.py -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
INFO  [plombery.14-download_and_delete_mp4] 已下载：configuration_deepseek.py -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\configuration_deepseek.py
正在下载：figures/benchmark.png
INFO  [plombery.14-download_and_delete_mp4] 正在下载：figures/benchmark.png
已下载：figures/benchmark.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
INFO  [plombery.14-download_and_delete_mp4] 已下载：figures/benchmark.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\benchmark.png
正在下载：figures/niah.png
INFO  [plombery.14-download_and_delete_mp4] 正在下载：figures/niah.png
已下载：figures/niah.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
INFO  [plombery.14-download_and_delete_mp4] 已下载：figures/niah.png -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\figures\niah.png
正在下载：inference/configs/config_16B.json
INFO  [plombery.14-download_and_delete_mp4] 正在下载：inference/configs/config_16B.json
已下载：inference/configs/config_16B.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
INFO  [plombery.14-download_and_delete_mp4] 已下载：inference/configs/config_16B.json -> tmp/deepseek-ai/DeepSeek-V3\models--deepseek-ai--DeepSeek-V3\snapshots\e815299b0bcbac849fa540c768ef21845365c9eb\inference\configs\config_16B.json
下载完成
INFO  [plombery.14-download_and_delete_mp4] 下载完成
tmp/deepseek-ai/DeepSeek-V3 已删除
INFO  [plombery.14-download_and_delete_mp4] tmp/deepseek-ai/DeepSeek-V3 已删除
INFO:     127.0.0.1:52036 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:60082 - "GET /api/runs/14 HTTP/1.1" 200 OK
INFO:     127.0.0.1:60082 - "GET /api/runs/14/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:63602 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:61504 - "GET /api/runs/14 HTTP/1.1" 200 OK
INFO:     127.0.0.1:51994 - "GET /api/runs/14/logs HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [7128]
INFO:     Started server process [28468]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:64251 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Alembic migrations complete.
INFO:     127.0.0.1:60660 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:57780 - "GET /api/runs/14 HTTP/1.1" 200 OK
INFO:     127.0.0.1:50220 - "GET /api/runs/14/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:50220 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:57780 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:57780 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:57780 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #15 via trigger `_manual`
INFO  [plombery.15] Executing pipeline `download_pipeline` #15 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.15] Executing task download_and_delete_mp4
Running download_and_delete_mp4 at 2025-12-09 18:44:09.718535
INFO  [plombery.15-download_and_delete_mp4] Running download_and_delete_mp4 at 2025-12-09 18:44:09.718535
仓库文件总数：185
INFO  [plombery.15-download_and_delete_mp4] 仓库文件总数：185
下载完成
INFO  [plombery.15-download_and_delete_mp4] 下载完成
tmp/deepseek-ai/DeepSeek-V3 已删除
INFO  [plombery.15-download_and_delete_mp4] tmp/deepseek-ai/DeepSeek-V3 已删除
INFO:     127.0.0.1:57780 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:50220 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:57780 - "GET /api/runs/15 HTTP/1.1" 200 OK
INFO:     127.0.0.1:57780 - "GET /api/runs/15/logs HTTP/1.1" 200 OK
INFO:     127.0.0.1:59831 - "GET /api/pipelines/download_pipeline HTTP/1.1" 200 OK
INFO:     127.0.0.1:63162 - "GET /api/runs/15 HTTP/1.1" 200 OK
INFO:     127.0.0.1:58312 - "GET /api/runs/15/logs HTTP/1.1" 200 OK
INFO:     Shutting down
INFO:     Waiting for application shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [28468]
INFO:     Started server process [5764]
INFO:     Waiting for application startup.
Running all migrations from base to head...
INFO  [alembic.runtime.migration] Context impl SQLiteImpl.
INFO  [alembic.runtime.migration] Will assume non-transactional DDL.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:60499 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
Alembic migrations complete.
INFO:     127.0.0.1:61170 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:56516 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:56516 - "GET / HTTP/1.1" 304 Not Modified
INFO:     127.0.0.1:62201 - "WebSocket /ws/socket.io/?EIO=4&transport=websocket" [accepted]
INFO:     127.0.0.1:56516 - "GET /api/auth/whoami HTTP/1.1" 200 OK
INFO:     127.0.0.1:56516 - "GET /api/pipelines/ HTTP/1.1" 200 OK
INFO:     127.0.0.1:61170 - "GET /api/runs/?pipeline_id=&trigger_id= HTTP/1.1" 200 OK
INFO:     127.0.0.1:61170 - "GET /api/pipelines/download_pipeline/input-schema HTTP/1.1" 200 OK
INFO:     127.0.0.1:61170 - "POST /api/pipelines/download_pipeline/run HTTP/1.1" 200 OK
Executing pipeline `download_pipeline` #16 via trigger `_manual`
INFO  [plombery.16] Executing pipeline `download_pipeline` #16 via trigger `_manual`
Executing task download_and_delete_mp4
INFO  [plombery.16] Executing task download_and_delete_mp4
Running download_and_delete_mp4 at 2025-12-09 18:44:56.657904
INFO  [plombery.16-download_and_delete_mp4] Running download_and_delete_mp4 at 2025-12-09 18:44:56.657904
仓库文件总数：185
INFO  [plombery.16-download_and_delete_mp4] 仓库文件总数：185
正在下载：model-00003-of-000163.safetensors
INFO  [plombery.16-download_and_delete_mp4] 正在下载：model-00003-of-000163.safetensors
E:\apps\miniconda3\Lib\site-packages\huggingface_hub\utils\_validators.py:186: UserWarning: The `resume_download` argument is deprecated and ignored in `hf_hub_download`. Downloads always resume whenever possible.
  warnings.warn(
